<!DOCTYPE html>
<html lang="en-us">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>A Demonstration of Overfitting</title>
<meta name="description" content="Keh-Harng Feng&#39;s Personal blog about Data and Statistics">
<meta name="generator" content="Hugo 0.19" />
<meta property="og:title" content="A Demonstration of Overfitting" />
<meta property="og:description" content="In the beginning, there was noise…A Simplified SimulationModel 1: Model every little thing from the instrument!Model 2: Include all features!Model 3: Simple structure with only the relevant feature.Performance Evaluation (Validation)DiscussionIf you work with data and do any sort of model building, no doubt you have seen the word “overfitting” floating about. What is it and why do we need to care?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://fengkehh.github.io/post/2017-06-30-overfitting/" />



<meta property="article:published_time" content="2017-06-30T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2017-06-30T00:00:00&#43;00:00"/>











<link rel="dns-prefetch" href="//fonts.googleapis.com" />

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,700" type="text/css" media="all" />
<link rel="stylesheet" href="https://fengkehh.github.io/css/style.css" type="text/css" media="all" />
<link rel="stylesheet" type='text/css' href="../../css/style.css" type="text/css" media="all" />
<link rel="stylesheet" type='text/css' href="css/style.css" type="text/css" media="all" />
<script type="text/javascript" src="https://fengkehh.github.io/js/scripts.js"></script>

<link rel="stylesheet" href="https://fengkehh.github.io/css/agate.css">
<script src="https://fengkehh.github.io/js/highlight.pack.js"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>

</head>
<body class="body body-right-sidebar mobile" itemscope="itemscope" itemtype="http://schema.org/WebPage">
	<div class="container container-outer">
		<header class="header" itemscope="itemscope" itemtype="http://schema.org/WPHeader">
			<div class="container container-inner clearfix">
				<div class="logo" role="banner" itemscope="itemscope" itemtype="http://schema.org/Brand">
					<a class="logo__link" href="https://fengkehh.github.io/" title="A Song of Numbers and Graphs" rel="home">
						<h1 class="logo__title">A Song of Numbers and Graphs</h1>
						<h2 class="logo__tagline">A Blog about Data Analysis</h2>
					</a>
				</div>
			</div>
			<nav class="menu" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
	<ul class="menu__list">
		<li class="menu__item "><a class="menu__link" href="../../categories/posts/">BLOG POSTS</a></li>
		<li class="menu__item "><a class="menu__link" href="../../categories/projects/">PROJECTS</a></li>
		<li class="menu__item "><a class="menu__link" href="../../about/">ABOUT THIS BLOG</a></li>
	</ul>
</nav>
		</header>
		<div class="wrapper clearfix">

<div class="main-content content" role="main" itemprop="mainContentOfPage">
	<article class="post">
		<header class="post__header clearfix">
			<h1 class="post__title">A Demonstration of Overfitting</h1>
			<p class="post__meta meta">
				<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
				<time class="post__meta-date" datetime="2017-06-30 00:00:00 &#43;0000 UTC">June 30, 2017</time>
				<span class="post__meta-categories meta-categories">
					<svg class="icon icon-category" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
					<a class="meta-categories__link" href="../../categories/posts" rel="category">Posts</a></span>
			</p>
		</header>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="m4.73135 3.3795002q0-.5597-.39604-.9557-.39604-.3961-.95577-.3961-.55974 0-.95578.3961-.39604.396-.39604.9557 0 .5598.39604.9558.39604.3961.95578.3961.55973 0 .95577-.3961.39604-.396.39604-.9558zm11.26865 6.0832q0 .5596998-.39076.9504998l-5.18548 5.196q-.41188.3908-.9610504.3908-.55974 0-.9505-.3908l-7.5511496-7.5616998q-.40132-.3907-.68119-1.0666-.27987-.6759-.27987-1.2357v-4.3934q0-.54920004.40132-.95050004.40132-.4013.9505-.4013h4.39339q.55974 0 1.23565.2799.67591.2798 1.07723.6812l7.55115 7.54060004q.39076.4118.39076.961z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link" href="../../tags/r/" rel="tag">R</a></li>
		<li class="tags__item"><a class="tags__link" href="../../tags/beginner/" rel="tag">Beginner</a></li>
		<li class="tags__item"><a class="tags__link" href="../../tags/overfitting/" rel="tag">Overfitting</a></li>
		<li class="tags__item"><a class="tags__link" href="../../tags/machine-learning/" rel="tag">Machine Learning</a></li>
		<li class="tags__item"><a class="tags__link" href="../../tags/decision-tree/" rel="tag">Decision Tree</a></li>
	</ul>
</div>

		<div class="post__content clearfix">
			<div id="TOC">
<ul>
<li><a href="#in-the-beginning-there-was-noise">In the beginning, there was noise…</a></li>
<li><a href="#a-simplified-simulation">A Simplified Simulation</a><ul>
<li><a href="#model-1-model-every-little-thing-from-the-instrument">Model 1: Model every little thing from the instrument!</a></li>
<li><a href="#model-2-include-all-features">Model 2: Include all features!</a></li>
<li><a href="#model-3-simple-structure-with-only-the-relevant-feature.">Model 3: Simple structure with only the relevant feature.</a></li>
<li><a href="#performance-evaluation-validation">Performance Evaluation (Validation)</a></li>
</ul></li>
<li><a href="#discussion">Discussion</a></li>
</ul>
</div>
<p>If you work with data and do any sort of model building, no doubt you have seen the word “overfitting” floating about. What is it and why do we need to care? Look on to find out!</p>
<div id="in-the-beginning-there-was-noise" class="section level1">
<h1>In the beginning, there was noise…</h1>
<p>Imagine you have a metal coin. The coin is coated with a very thin layer of rubber on only one side. You decide that you want to toss the coin in the air 1000 times and record the sound it makes when it lands on your table. It’s not a stretch to think it’s in fact possible to tell which side of the coin is ultimately facing up from the sound alone. The goal is predict which side is up using just the sound instead of Mark I Eyeballs.</p>
<p>Unfortunately you have some important business to attend to so you ask your friend, Mad Scientist Mike, to conduct the experiment in your stead. When you come back, you find out that the microphone is also picking up Mike walking around in the room and the birds chirping outside. Furthermore, Mike has decided to be true to his name and recorded water pressure and voltage deviation of the house in the mean time.</p>
<p>You are now faced with a dilemma. Your gut feeling tells you some of the data you have may not be connected to your experiment outcomes. If that’s the case, then they are part of your measurements makes them unwanted <strong>noise</strong>. If you are not careful when dealing with the noise, your model might become:</p>
<ol style="list-style-type: decimal">
<li>Overtly complicated, with parts and terms trying to explain the noise rather than actually important features.</li>
<li>Poor in making predictions. Any slight fluctuations due to noise can cause the model to overreact!</li>
</ol>
</div>
<div id="a-simplified-simulation" class="section level1">
<h1>A Simplified Simulation</h1>
<p>Let’s use a simulated data set to help us understand what may happen.</p>
<pre class="r"><code># Load all required libraries.
library(&quot;caret&quot;)
library(&quot;rpart&quot;)
library(&quot;rpart.plot&quot;)

set.seed(123)
toss &lt;- rbinom(1000, 1, 0.5)
inst &lt;- rnorm(1000) + toss
volt &lt;- rnorm(1000)
water &lt;- rnorm(1000)

toss_fac &lt;- factor(toss, labels = c(&quot;tail&quot;, &quot;head&quot;))

data &lt;- data.frame(inst = inst, volt = volt, water = water, response = toss_fac)</code></pre>
<p>The response is 1000 tosses drawn from a binomial distribution and factored into either <code>tail</code> or <code>head</code>. The predictors are</p>
<ol style="list-style-type: decimal">
<li>The <code>inst</code>rument measurement modeled simply as the response + a normally distributed signal noise.</li>
<li>The deviation in <code>volt</code>age in the electrical circuits of the house. Modeled as a standard normal distribution.</li>
<li>The deviation in <code>water</code> pressure of the house. Modeled as a standard normal distribution.</li>
</ol>
<p>The data is then split into training and vadliation sets.</p>
<pre class="r"><code>inTrain &lt;- createDataPartition(toss_fac, p = 0.6, list = FALSE)

data.train &lt;- data[inTrain, ]
data.validation &lt;- data[-inTrain, ]</code></pre>
<p>I am now going to train three decision tree models using the training sets, each demonstrating a different aspect.</p>
<div id="model-1-model-every-little-thing-from-the-instrument" class="section level2">
<h2>Model 1: Model every little thing from the instrument!</h2>
<p>This model will use a huge amount of splitting and very <em>small</em> leafs to fit the training data. The goal of this model is to try to achieve very high accuracy on the training set using the instrument measurement at all costs.</p>
<p>First we will set up the hyper-parameters for the tree model.</p>
<pre class="r"><code>treeCon.over &lt;- rpart.control(minsplit = 2, minbucket = 1, cp = 0, xval = 10)</code></pre>
<p>The exact meaning of the parameters are not super important but here it is:</p>
<p><code>minsplit</code>: controls how many training data points a node has to have before the algorithm can attempt to grow branches from it.</p>
<p><code>minbucket</code>: how many training data points a leaf must at least have in the final tree.</p>
<p><code>cp</code>: controls how good a branch must be before it can be kept. Each branch must increase model quality (ie: R^2) by at least <code>cp</code> or it will be cut-off.</p>
<p><code>xval</code>: number of cross-validation folds to be used for pruning (don’t worry if you don’t know what it means).</p>
<p>So with this in mind, our tree is pretty much set up to be as complex as possible. Here’s the code to build the model:</p>
<pre class="r"><code>set.seed(1)
tree1 &lt;- rpart(response ~ inst, data = data.train, control = treeCon.over)</code></pre>
<p>Notice that I have thrown away the other stuff Mike collected such as voltage and water pressure. The model is built using the noisy instrument signal as its sole predictor. Let us plot the tree structure.</p>
<pre class="r"><code>rpart.plot(tree1)</code></pre>
<p><img src="../../post/2017-06-30-overfitting_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Whoa! That is indeed an extremely complex tree. However, what will the effect be on training set accuracy? Let’s find out:</p>
<pre class="r"><code>pred.train1 &lt;- predict(tree1, data.train, type = &quot;class&quot;)
conMat1 &lt;- confusionMatrix(pred.train1, data.train$response)
conMat1</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction tail head
##       tail  305    3
##       head    0  293
##                                         
##                Accuracy : 0.995         
##                  95% CI : (0.985, 0.999)
##     No Information Rate : 0.507         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.99          
##  Mcnemar&#39;s Test P-Value : 0.248         
##                                         
##             Sensitivity : 1.000         
##             Specificity : 0.990         
##          Pos Pred Value : 0.990         
##          Neg Pred Value : 1.000         
##              Prevalence : 0.507         
##          Detection Rate : 0.507         
##    Detection Prevalence : 0.512         
##       Balanced Accuracy : 0.995         
##                                         
##        &#39;Positive&#39; Class : tail          
## </code></pre>
<p>An accuracy of 0.995. That is extremely high. Should we choose this one as our final model? Let’s build a couple other models first.</p>
</div>
<div id="model-2-include-all-features" class="section level2">
<h2>Model 2: Include all features!</h2>
<p>Let’s change some hyper-parameters:</p>
<pre class="r"><code>treeCon &lt;- rpart.control(minsplit = 10, minbucket = 3, cp = 0.01, xval = 10)</code></pre>
<p>So we have made each branching node and leaf larger, with also a higher quality improvement requirement during pruning. Let’s build the model now.</p>
<pre class="r"><code>set.seed(1)
tree2 &lt;- rpart(response ~ inst + volt + water, data = data.train, control = treeCon)</code></pre>
<p>Notice that although our hyper-parameters demand an overall decrease in structural complexity of the tree, we are now also using the other features Mike collected such as voltage and water pressure deviations to construct the model. Here’s the final strucutre:</p>
<pre class="r"><code>rpart.plot(tree2)</code></pre>
<p><img src="../../post/2017-06-30-overfitting_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>As expected, this is a much simpler tree in terms of sturctural complexity (albeit still pretty complex). However it does make use of all three features, some of them we suspect to be useless. What about its training set accuracy?</p>
<pre class="r"><code>pred.train2 &lt;- predict(tree2, data.train, type = &quot;class&quot;)
conMat2 &lt;- confusionMatrix(pred.train2, data.train$response)
conMat2</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction tail head
##       tail  248   76
##       head   57  220
##                                         
##                Accuracy : 0.779         
##                  95% CI : (0.743, 0.811)
##     No Information Rate : 0.507         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.557         
##  Mcnemar&#39;s Test P-Value : 0.119         
##                                         
##             Sensitivity : 0.813         
##             Specificity : 0.743         
##          Pos Pred Value : 0.765         
##          Neg Pred Value : 0.794         
##              Prevalence : 0.507         
##          Detection Rate : 0.413         
##    Detection Prevalence : 0.539         
##       Balanced Accuracy : 0.778         
##                                         
##        &#39;Positive&#39; Class : tail          
## </code></pre>
<p>With an accuracy of 0.7787 it seems to be markedly worse than model 1…or is it? At the very least it still has quite a bit of predictive power since it’s accuracy is significantly higher than the <em>No Information Rate</em>. Let’s build one final model.</p>
</div>
<div id="model-3-simple-structure-with-only-the-relevant-feature." class="section level2">
<h2>Model 3: Simple structure with only the relevant feature.</h2>
<p>No changes will be made to the hyper-parameters here. Instead, we will train the model with just one difference:</p>
<pre class="r"><code>set.seed(1)
tree3 &lt;- rpart(response ~ inst, data = data.train, control = treeCon)</code></pre>
<p>This tree is built with the same complexity parameters as our last tree, but only using the instrument measurements as its feature. Let’s check out its structure:</p>
<pre class="r"><code>rpart.plot(tree3)</code></pre>
<p><img src="../../post/2017-06-30-overfitting_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Clearly this is the simplest tree by far in terms of both structure and feature usage. How about its accuracy on the training set?</p>
<pre class="r"><code>pred.train3 &lt;- predict(tree3, data.train, type = &quot;class&quot;)
conMat3 &lt;- confusionMatrix(pred.train3, data.train$response)
conMat3</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction tail head
##       tail  262  123
##       head   43  173
##                                         
##                Accuracy : 0.724         
##                  95% CI : (0.686, 0.759)
##     No Information Rate : 0.507         
##     P-Value [Acc &gt; NIR] : &lt; 2e-16       
##                                         
##                   Kappa : 0.445         
##  Mcnemar&#39;s Test P-Value : 8.7e-10       
##                                         
##             Sensitivity : 0.859         
##             Specificity : 0.584         
##          Pos Pred Value : 0.681         
##          Neg Pred Value : 0.801         
##              Prevalence : 0.507         
##          Detection Rate : 0.436         
##    Detection Prevalence : 0.641         
##       Balanced Accuracy : 0.722         
##                                         
##        &#39;Positive&#39; Class : tail          
## </code></pre>
<p>Uh oh. With an accuracy of 0.7238 this is by far the worst model we have built! I guess it’s clear we should use the big tree from model 1 as our final model, right? Oh wait, we split the data into training and validation set! Since the models are all built on the training set they have no ideas what the validation set looks like. If we feed the models the validation set we can make actual predictions with them and get a sense on its predictive accuracy. How exciting! Let’s do it.</p>
</div>
<div id="performance-evaluation-validation" class="section level2">
<h2>Performance Evaluation (Validation)</h2>
<p>Here’s the code to make predictions on the validation set and compute the prediction statistics:</p>
<pre class="r"><code>pred.validation.1 &lt;- predict(tree1, data.validation, type = &quot;class&quot;)
pred.validation.2 &lt;- predict(tree2, data.validation, type = &quot;class&quot;)
pred.validation.3 &lt;- predict(tree3, data.validation, type = &quot;class&quot;)

confMat.valid.1 &lt;- confusionMatrix(pred.validation.1, data.validation$response)
confMat.valid.2 &lt;- confusionMatrix(pred.validation.2, data.validation$response)
confMat.valid.3 &lt;- confusionMatrix(pred.validation.3, data.validation$response)</code></pre>
<p>I am just going to list the accuracies below in a table:</p>
<pre class="r"><code>df &lt;- data.frame(Model = c(&quot;Model 1&quot;, &quot;Model 2&quot;, &quot;Model 3&quot;), Accuracy = c(confMat.valid.1$overall[1], 
    confMat.valid.2$overall[1], confMat.valid.3$overall[1]))

kable(df)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="right">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Model 1</td>
<td align="right">0.6065</td>
</tr>
<tr class="even">
<td align="left">Model 2</td>
<td align="right">0.6692</td>
</tr>
<tr class="odd">
<td align="left">Model 3</td>
<td align="right">0.6792</td>
</tr>
</tbody>
</table>
<p>Well well, the table has turned! The big tree in model1, although has an amazing training set accuracy, is now the definitive last place when it comes to making predictions on the validation set. The tree with the worst training set performance, the tree with low complexity parameters and only using the instrument measurement as its feature, is now the best performer. Why is that?</p>
</div>
</div>
<div id="discussion" class="section level1">
<h1>Discussion</h1>
<p>By now you probably have a good idea to the answer already. The first two trees overfit the data (especially the first one). The first model contains too many nodes and leafs. The result is it is able to fit every single data point in the training set into single leafs by itself and simply look them up. No wonder it has such amazing (and grossly inflated) training set accuracy. However, when it comes to making actual predictions on the validation set all the noise throws it off and causes it to overreact on noisy signals that don’t have any real effect on the response. The result is terrible predictive accuracy.</p>
<p>Although the second tree tries to avoid very complex structure, it uses features that are clearly useless in predicting the response (water pressure and voltage deviations…really, Mike?). The good thing is the pruning process is able to catch some of these and cut them off the trees so it doesn’t make too much of a negative impact on its prediction accuracy.</p>
<p>Nevertheless, you can see that model 3, with the simplest structure and using only the relevant feature, turns out to be the best one in the end. This simple structure is achieved by <em>tuning hyper-parameters</em> and using only relevant features aka <em>feature selection</em>. In this case, they are largely done by experience and logic. I know beforehand that the data is noisy and two of the features are useless, so all I need to do is just selecting sensible model parameter values relative to my other choices and get rid of useless features. This is actually an <em>excellent</em> way to build models as it is not done using information obtained directly from the data so there is no risk of overfitting.</p>
<p>For a model builder, the biggest problem with overfitting is it contaminates model performance assessment which leads to making the wrong choice. Think back on the inflated training set accuracies. If I used the training set accuracy as the performance indicator I would have chosen the worst model in the end. Some may ask, what if I tweak model parameters and select features using the statistics produced by a previous model? The truth is, <strong>whenever you are using the data to gain information about what your model should be, what features you shoud select etc, you can potentially overfit</strong>. For example, now I know the prediction accuracies of the three models on the validation set, if I go back, tweak some parameters/select some features and retrain the model on the training set to improve my prediction accuracy on the validation set, the validation set accuracy is likely going to be biased due to overfitting as well. Why? Because the accuracy assessment on the validation set is information gleaned from the validation set. By going back to make model tweaks based on it, information in the validation set is now spilling over to the model training process and the validation set accuracy will likely become biased just like the training set accuracies.</p>
<p>Wait, does this mean we can only use the validation set to produce an accurate estimate of model performance ONCE? Well, technically, yes. However, there are techniques to repeatedly produce accurate performance estimates and avoid/delay bias caused by overfitting such as <strong>resampling</strong>. We shall see this in another post.</p>
</div>

		</div>
	</article>
	
<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Keh-Harng Feng avatar" src="https://fengkehh.github.io/img/avatar.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Keh-Harng Feng</span>
	</div>
	<div class="authorbox__description">
		Keh-Harng Feng is aspiring to become a data scientist. He graduated from York University with a MSc in Physics and University of Toronto with a BSc in Computer Science and Physics.
	</div>
</div>
	
<nav class="post-nav row clearfix" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
	<div class="post-nav__item post-nav__item--prev col-1-2">
		<a class="post-nav__link" href="https://fengkehh.github.io/post/2017-04-26-the-poor-pigs-problem/" rel="prev"><span class="post-nav__caption">«Previous</span><p class="post-nav__post-title">The Poor Pigs Problem</p></a>
	</div>
</nav>

	
<div class="comments">
	<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'datakhf';
    var disqus_identifier = 'https:\/\/fengkehh.github.io\/post\/2017-06-30-overfitting\/';
    var disqus_title = 'A Demonstration of Overfitting';
    var disqus_url = 'https:\/\/fengkehh.github.io\/post\/2017-06-30-overfitting\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

</div>

<aside class="sidebar" itemscope="itemscope" itemtype="http://schema.org/WPSideBar">
	
	
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="../../post/2017-06-30-overfitting/">A Demonstration of Overfitting</a></li>
			<li class="widget__item"><a class="widget__link" href="../../post/2017-04-26-the-poor-pigs-problem/">The Poor Pigs Problem</a></li>
			<li class="widget__item"><a class="widget__link" href="../../post/2017-03-30-can-car-transmission-affect-fuel-efficiency/">Can Car Transmission Affect Fuel Efficiency?</a></li>
			<li class="widget__item"><a class="widget__link" href="../../post/2017-03-21-the-effects-of-vitamin-c-supplements-on-guinea-pig-odontoblast-lengths/">The Effects of Vitamin C Supplements on Guinea Pig Odontoblast Lengths</a></li>
			<li class="widget__item"><a class="widget__link" href="../../post/2017-03-16-how-this-blog-is-made-part-ii/">Making A Blog Site with RStudio, R Markdown and Blogdown Part II</a></li>
			<li class="widget__item"><a class="widget__link" href="../../post/2017-03-15-how-this-blog-is-made/">Making A Blog Site with RStudio, R Markdown and Blogdown Part I</a></li>
			<li class="widget__item"><a class="widget__link" href="../../post/">Posts</a></li>
		</ul>
	</div>
</div>
	
	
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/algorithm" title="algorithm">algorithm</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/anova" title="anova">anova</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/beginner" title="beginner">beginner</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/blogdown" title="blogdown">blogdown</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/bootstrap" title="bootstrap">bootstrap</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/decision-tree" title="decision-tree">decision-tree</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/github" title="github">github</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/hugo" title="hugo">hugo</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/hypothesis-test" title="hypothesis-test">hypothesis-test</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/machine-learning" title="machine-learning">machine-learning</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/model-selection" title="model-selection">model-selection</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/multivariate-linear-regression" title="multivariate-linear-regression">multivariate-linear-regression</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/overfitting" title="overfitting">overfitting</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/puzzle" title="puzzle">puzzle</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/r" title="r">r</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/r-markdown" title="r-markdown">r-markdown</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/residual-analysis" title="residual-analysis">residual-analysis</a>
		<a class="widget__link widget__link--taglist" href="https://fengkehh.github.io/tags/statistical-inference" title="statistical-inference">statistical-inference</a>
	</div>
</div>
</aside>
	</div>
		<footer class="footer" itemscope="itemscope" itemtype="http://schema.org/WPFooter">
			<div class="container container-inner">
				<p class="footer__copyright">&copy; 2017 Keh-Harng Feng. Based on <a href="//wordpress.org/themes/mh-magazine-lite/" target="_blank" rel="nofollow noopener noreferrer">MH Magazine lite</a>.</p>
			</div>
		</footer>
	</div>

<script>
	var navigation = responsiveNav(".menu", {
		navClass: "menu--collapse",
	});
</script>
<script type="text/x-mathjax-config">

    MathJax.Hub.Config({

      tex2jax: {

        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']

      }

    });

</script>

<script type="text/javascript"

      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">

</script>


<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-96579173-1', 'auto');
ga('send', 'pageview');
</script>

</body>
</html>