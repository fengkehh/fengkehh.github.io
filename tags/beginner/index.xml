<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Beginner on A Song of Numbers and Graphs</title>
    <link>https://fengkehh.github.io/tags/beginner/index.xml</link>
    <description>Recent content in Beginner on A Song of Numbers and Graphs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://fengkehh.github.io/tags/beginner/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Demonstration of Overfitting</title>
      <link>https://fengkehh.github.io/post/2017-06-30-overfitting/</link>
      <pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://fengkehh.github.io/post/2017-06-30-overfitting/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#in-the-beginning-there-was-noise&#34;&gt;In the beginning, there was noise…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-simplified-simulation&#34;&gt;A Simplified Simulation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#model-1-model-every-little-thing-from-the-instrument&#34;&gt;Model 1: Model every little thing from the instrument!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-2-include-all-features&#34;&gt;Model 2: Include all features!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-3-simple-structure-with-only-the-relevant-feature.&#34;&gt;Model 3: Simple structure with only the relevant feature.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#performance-evaluation-validation&#34;&gt;Performance Evaluation (Validation)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#discussion&#34;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;If you work with data and do any sort of model building, no doubt you have seen the word “overfitting” floating about. What is it and why do we need to care? Look on to find out!&lt;/p&gt;
&lt;div id=&#34;in-the-beginning-there-was-noise&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;In the beginning, there was noise…&lt;/h1&gt;
&lt;p&gt;Imagine you have a metal coin. The coin is coated with a very thin layer of rubber on only one side. You decide that you want to toss the coin in the air 1000 times and record the sound it makes when it lands on your table. It’s not a stretch to think it’s in fact possible to tell which side of the coin is ultimately facing up from the sound alone. The goal is predict which side is up using just the sound instead of Mark I Eyeballs.&lt;/p&gt;
&lt;p&gt;Unfortunately you have some important business to attend to so you ask your friend, Mad Scientist Mike, to conduct the experiment in your stead. When you come back, you find out that the microphone is also picking up Mike walking around in the room and the birds chirping outside. Furthermore, Mike has decided to be true to his name and recorded water pressure and voltage deviation of the house during the coin toss.&lt;/p&gt;
&lt;p&gt;You are now faced with a dilemma. Your gut feeling tells you some of the data you have may not be connected to your experiment outcomes. If that’s the case, then the fact that they are part of your measurements makes them unwanted &lt;strong&gt;noise&lt;/strong&gt;. If you are not careful when dealing with the noise, your model might become:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Overtly complicated, with parts and terms trying to explain the noise rather than actually important features.&lt;/li&gt;
&lt;li&gt;Poor in making predictions. Any slight fluctuations due to noise can cause the model to overreact!&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;a-simplified-simulation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A Simplified Simulation&lt;/h1&gt;
&lt;p&gt;Let’s use a simulated data set to help us understand what may happen.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load all required libraries.
library(&amp;quot;caret&amp;quot;)
library(&amp;quot;rpart&amp;quot;)
library(&amp;quot;rpart.plot&amp;quot;)

set.seed(123)
toss &amp;lt;- rbinom(1000, 1, 0.5)
inst &amp;lt;- rnorm(1000) + toss
volt &amp;lt;- rnorm(1000)
water &amp;lt;- rnorm(1000)

toss_fac &amp;lt;- factor(toss, labels = c(&amp;quot;tail&amp;quot;, &amp;quot;head&amp;quot;))

data &amp;lt;- data.frame(inst = inst, volt = volt, water = water, response = toss_fac)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The response is 1000 tosses drawn from a binomial distribution and factored into either &lt;code&gt;tail&lt;/code&gt; or &lt;code&gt;head&lt;/code&gt;. The predictors are&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The &lt;code&gt;inst&lt;/code&gt;rument measurement modeled simply as the response + a normally distributed signal noise.&lt;/li&gt;
&lt;li&gt;The deviation in &lt;code&gt;volt&lt;/code&gt;age in the electrical circuits of the house. Modeled as a standard normal distribution.&lt;/li&gt;
&lt;li&gt;The deviation in &lt;code&gt;water&lt;/code&gt; pressure of the house. Modeled as a standard normal distribution.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The data is then split into training and vadliation sets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inTrain &amp;lt;- createDataPartition(toss_fac, p = 0.6, list = FALSE)

data.train &amp;lt;- data[inTrain, ]
data.validation &amp;lt;- data[-inTrain, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am now going to train three decision tree models using the training sets, each demonstrating a different aspect.&lt;/p&gt;
&lt;div id=&#34;model-1-model-every-little-thing-from-the-instrument&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model 1: Model every little thing from the instrument!&lt;/h2&gt;
&lt;p&gt;This model will use a huge amount of splitting and very &lt;em&gt;small&lt;/em&gt; leafs to fit the training data. The goal of this model is to try to achieve very high accuracy on the training set using the instrument measurement at all costs.&lt;/p&gt;
&lt;p&gt;First we will set up the hyper-parameters for the tree model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;treeCon.over &amp;lt;- rpart.control(minsplit = 2, minbucket = 1, cp = 0, xval = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The exact meaning of the parameters are not super important but here it is:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;minsplit&lt;/code&gt;: controls how many training data points a node has to have before the algorithm can attempt to grow branches from it.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;minbucket&lt;/code&gt;: how many training data points a leaf must at least have in the final tree.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cp&lt;/code&gt;: controls how good a branch must be before it can be kept. Each branch must increase model quality (ie: R^2) by at least &lt;code&gt;cp&lt;/code&gt; or it will be cut-off.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;xval&lt;/code&gt;: number of cross-validation folds to be used for pruning (don’t worry if you don’t know what it means).&lt;/p&gt;
&lt;p&gt;So with this in mind, our tree is pretty much set up to be as complex as possible. Here’s the code to build the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
tree1 &amp;lt;- rpart(response ~ inst, data = data.train, control = treeCon.over)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that I have thrown away the other stuff Mike collected such as voltage and water pressure. The model is built using the noisy instrument signal as its sole predictor. Let us plot the tree structure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rpart.plot(tree1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/2017-06-30-overfitting_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Whoa! That is indeed an extremely complex tree. However, what will the effect be on training set accuracy? Let’s find out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pred.train1 &amp;lt;- predict(tree1, data.train, type = &amp;quot;class&amp;quot;)
conMat1 &amp;lt;- confusionMatrix(pred.train1, data.train$response)
conMat1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Confusion Matrix and Statistics
## 
##           Reference
## Prediction tail head
##       tail  305    3
##       head    0  293
##                                         
##                Accuracy : 0.995         
##                  95% CI : (0.985, 0.999)
##     No Information Rate : 0.507         
##     P-Value [Acc &amp;gt; NIR] : &amp;lt;2e-16        
##                                         
##                   Kappa : 0.99          
##  Mcnemar&amp;#39;s Test P-Value : 0.248         
##                                         
##             Sensitivity : 1.000         
##             Specificity : 0.990         
##          Pos Pred Value : 0.990         
##          Neg Pred Value : 1.000         
##              Prevalence : 0.507         
##          Detection Rate : 0.507         
##    Detection Prevalence : 0.512         
##       Balanced Accuracy : 0.995         
##                                         
##        &amp;#39;Positive&amp;#39; Class : tail          
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An accuracy of 0.995. That is extremely high. Should we choose this one as our final model? Let’s build a couple other models first.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-2-include-all-features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model 2: Include all features!&lt;/h2&gt;
&lt;p&gt;Let’s change some hyper-parameters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;treeCon &amp;lt;- rpart.control(minsplit = 10, minbucket = 3, cp = 0.01, xval = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we have made each branching node and leaf larger, with also a higher quality improvement requirement during pruning. Let’s build the model now.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
tree2 &amp;lt;- rpart(response ~ inst + volt + water, data = data.train, control = treeCon)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that although our hyper-parameters demand an overall decrease in structural complexity of the tree, we are now also using the other features Mike collected such as voltage and water pressure deviations to construct the model. Here’s the final strucutre:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rpart.plot(tree2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/2017-06-30-overfitting_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, this is a much simpler tree in terms of sturctural complexity (albeit still pretty complex). However it does make use of all three features, some of them we suspect to be useless. What about its training set accuracy?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pred.train2 &amp;lt;- predict(tree2, data.train, type = &amp;quot;class&amp;quot;)
conMat2 &amp;lt;- confusionMatrix(pred.train2, data.train$response)
conMat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Confusion Matrix and Statistics
## 
##           Reference
## Prediction tail head
##       tail  248   76
##       head   57  220
##                                         
##                Accuracy : 0.779         
##                  95% CI : (0.743, 0.811)
##     No Information Rate : 0.507         
##     P-Value [Acc &amp;gt; NIR] : &amp;lt;2e-16        
##                                         
##                   Kappa : 0.557         
##  Mcnemar&amp;#39;s Test P-Value : 0.119         
##                                         
##             Sensitivity : 0.813         
##             Specificity : 0.743         
##          Pos Pred Value : 0.765         
##          Neg Pred Value : 0.794         
##              Prevalence : 0.507         
##          Detection Rate : 0.413         
##    Detection Prevalence : 0.539         
##       Balanced Accuracy : 0.778         
##                                         
##        &amp;#39;Positive&amp;#39; Class : tail          
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With an accuracy of 0.7787 it seems to be markedly worse than model 1…or is it? At the very least it still has quite a bit of predictive power since it’s accuracy is significantly higher than the &lt;em&gt;No Information Rate&lt;/em&gt;. Let’s build one final model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-3-simple-structure-with-only-the-relevant-feature.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model 3: Simple structure with only the relevant feature.&lt;/h2&gt;
&lt;p&gt;No changes will be made to the hyper-parameters here. Instead, we will train the model with just one difference:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
tree3 &amp;lt;- rpart(response ~ inst, data = data.train, control = treeCon)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tree is built with the same complexity parameters as our last tree, but only using the instrument measurements as its feature. Let’s check out its structure:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rpart.plot(tree3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/2017-06-30-overfitting_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly this is the simplest tree by far in terms of both structure and feature usage. How about its accuracy on the training set?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pred.train3 &amp;lt;- predict(tree3, data.train, type = &amp;quot;class&amp;quot;)
conMat3 &amp;lt;- confusionMatrix(pred.train3, data.train$response)
conMat3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Confusion Matrix and Statistics
## 
##           Reference
## Prediction tail head
##       tail  262  123
##       head   43  173
##                                         
##                Accuracy : 0.724         
##                  95% CI : (0.686, 0.759)
##     No Information Rate : 0.507         
##     P-Value [Acc &amp;gt; NIR] : &amp;lt; 2e-16       
##                                         
##                   Kappa : 0.445         
##  Mcnemar&amp;#39;s Test P-Value : 8.7e-10       
##                                         
##             Sensitivity : 0.859         
##             Specificity : 0.584         
##          Pos Pred Value : 0.681         
##          Neg Pred Value : 0.801         
##              Prevalence : 0.507         
##          Detection Rate : 0.436         
##    Detection Prevalence : 0.641         
##       Balanced Accuracy : 0.722         
##                                         
##        &amp;#39;Positive&amp;#39; Class : tail          
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Uh oh. With an accuracy of 0.7238 this is by far the worst model we have built! I guess it’s clear we should use the big tree from model 1 as our final model, right? Oh wait, we split the data into training and validation set! Since the models are all built on the training set they have no ideas what the validation set looks like. If we feed the models the validation set we can make actual predictions with them and get a sense on its predictive accuracy. How exciting! Let’s do it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;performance-evaluation-validation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Performance Evaluation (Validation)&lt;/h2&gt;
&lt;p&gt;Here’s the code to make predictions on the validation set and compute the prediction statistics:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pred.validation.1 &amp;lt;- predict(tree1, data.validation, type = &amp;quot;class&amp;quot;)
pred.validation.2 &amp;lt;- predict(tree2, data.validation, type = &amp;quot;class&amp;quot;)
pred.validation.3 &amp;lt;- predict(tree3, data.validation, type = &amp;quot;class&amp;quot;)

confMat.valid.1 &amp;lt;- confusionMatrix(pred.validation.1, data.validation$response)
confMat.valid.2 &amp;lt;- confusionMatrix(pred.validation.2, data.validation$response)
confMat.valid.3 &amp;lt;- confusionMatrix(pred.validation.3, data.validation$response)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am just going to list the accuracies below in a table:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(Model = c(&amp;quot;Model 1&amp;quot;, &amp;quot;Model 2&amp;quot;, &amp;quot;Model 3&amp;quot;), Accuracy = c(confMat.valid.1$overall[1], 
    confMat.valid.2$overall[1], confMat.valid.3$overall[1]))

kable(df)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accuracy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Model 1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6065&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Model 2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6692&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Model 3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6792&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Well well, the table has turned! The big tree in model1, although has an amazing training set accuracy, is now the definitive last place when it comes to making predictions on the validation set. The tree with the worst training set performance, the tree with low complexity parameters and only using the instrument measurement as its feature, is now the best performer. Why is that?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;discussion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;By now you probably have a good idea to the answer already. The first two trees overfit the data (especially the first one). The first model contains too many nodes and leafs. The result is it is able to fit every single data point in the training set into single leafs by itself and simply look them up. No wonder it has such amazing (and grossly inflated) training set accuracy. However, when it comes to making actual predictions on the validation set all the noise throws it off and causes it to overreact on noisy signals that don’t have any real effect on the response. The result is terrible predictive accuracy.&lt;/p&gt;
&lt;p&gt;Although the second tree tries to avoid very complex structure, it uses features that are clearly useless in predicting the response (water pressure and voltage deviations…really, Mike?). The good thing is the pruning process is able to catch some of these and cut them off the trees so it doesn’t make too much of a negative impact on its prediction accuracy.&lt;/p&gt;
&lt;p&gt;Nevertheless, you can see that model 3, with the simplest structure and using only the relevant feature, turns out to be the best one in the end. This simple structure is achieved by &lt;em&gt;tuning hyper-parameters&lt;/em&gt; and using only relevant features aka &lt;em&gt;feature selection&lt;/em&gt;. In this case, they are largely done by experience and logic. I know beforehand that the data is noisy and two of the features are useless, so all I need to do is just selecting sensible model parameter values relative to my other choices and get rid of useless features. This is actually an &lt;em&gt;excellent&lt;/em&gt; way to build models as it is not done using information obtained directly from the data so there is no risk of overfitting.&lt;/p&gt;
&lt;p&gt;For a model builder, the biggest problem with overfitting is it contaminates model performance assessment which leads to making the wrong choice. Think back on the inflated training set accuracies. If I used the training set accuracy as the performance indicator I would have chosen the worst model in the end. Some may ask, what if I tweak model parameters and select features using the statistics produced by a previous model? The truth is, &lt;strong&gt;whenever you are using the data to gain information about what your model should be, what features you shoud select etc, you can potentially overfit&lt;/strong&gt;. For example, now I know the prediction accuracies of the three models on the validation set, if I go back, tweak some parameters/select some features and retrain the model on the training set to improve my prediction accuracy on the validation set, the validation set accuracy is likely going to be biased due to overfitting as well. Why? Because the accuracy assessment on the validation set is information gleaned from the validation set. By going back to make model tweaks based on it, information in the validation set is now spilling over to the model training process and the validation set accuracy will likely become biased just like the training set accuracies.&lt;/p&gt;
&lt;p&gt;Wait, does this mean we can only use the validation set to produce an accurate estimate of model performance ONCE? Well, technically, yes. However, there are techniques to repeatedly produce accurate performance estimates and avoid/delay bias caused by overfitting such as &lt;strong&gt;resampling&lt;/strong&gt;. We shall see this in another post.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Making A Blog Site with RStudio, R Markdown and Blogdown Part II</title>
      <link>https://fengkehh.github.io/post/2017-03-16-how-this-blog-is-made-part-ii/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://fengkehh.github.io/post/2017-03-16-how-this-blog-is-made-part-ii/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#blogdown-and-hugo&#34;&gt;Blogdown and Hugo&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#setup&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#github-pages&#34;&gt;Github (Pages)&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#setup-1&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#site-creation-submodule&#34;&gt;Site Creation &amp;amp; Submodule&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#setup-2&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#site-configuration-and-deployment&#34;&gt;Site Configuration and Deployment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;
&lt;p&gt;This is the continuation of &lt;a href=&#34;../2017-03-15-how-this-blog-is-made/&#34;&gt;Part I&lt;/a&gt;. In this section I am going to cover setting up &lt;em&gt;Blogdown&lt;/em&gt;, &lt;em&gt;Hugo&lt;/em&gt; and &lt;em&gt;Github Pages&lt;/em&gt; to start blogging. This is essentially a mix of the excellent guides by &lt;a href=&#34;https://proquestionasker.github.io/blog/Making_Site/&#34;&gt;Amber Thomas&lt;/a&gt;, &lt;a href=&#34;https://hjdskes.github.io/blog/update-deploying-hugo-on-personal-gh-pages/&#34;&gt;Jente Hidske&lt;/a&gt; and &lt;a href=&#34;http://robertmyles.github.io/2017/02/01/how-to-make-a-github-pages-blog-with-rstudio-and-hugo/&#34;&gt;Robert McDonnell&lt;/a&gt;. However if you want a one stop solution with some of my personal twists, here it is!&lt;/p&gt;
&lt;p&gt;I am going to assume you are using Microsoft Windows because that is what I use. The process should be largely the same for Linux and Mac OSX but you may need to install extra softwares such as &lt;em&gt;Homebrew&lt;/em&gt;. If you see an item like &lt;em&gt;&amp;lt; something &amp;gt;&lt;/em&gt;, that means replace it with whatever &lt;em&gt;something&lt;/em&gt; indicates (ie: your username, directory name etc etc) minus the angle brackets. Once you finished every step you should be able to access your online website at &lt;code&gt;https://&amp;lt;your username&amp;gt;.github.io/&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;blogdown-and-hugo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Blogdown and Hugo&lt;/h2&gt;
&lt;p&gt;Hugo is a static website delivery system. It is very easy to create a website with consistent theme and styling using Hugo. The only problem for us is that Hugo does NOT inherently support R Markdown. This is why we need Blogdown, the brainchild of Yihui Xie (aka Emperor of R Markdown, First of His Name), to bridge the water.&lt;/p&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setup&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Launch RStudio. Type the following command to install Blogdown and load it into R.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(c(&amp;#39;httpuv&amp;#39;, &amp;#39;devtools&amp;#39;))
devtools::install_github(&amp;quot;rstudio/blogdown&amp;quot;)
library(blogdown)&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Install Hugo using the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install_hugo()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Right now we can actually start generating a new site. However it is a good time to go set up our webhost first.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;github-pages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Github (Pages)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com&#34;&gt;Github&lt;/a&gt; is an online repository site utilizing the Git technology. Normally Github is used for version control in software development. However it has a lesser known functionality called Github Pages which is essentially free webhosting for static websites.&lt;/p&gt;
&lt;p&gt;Here’s a bit of tangent on how Github works. &lt;strong&gt;Skip straight to Setup if you are not interested.&lt;/strong&gt; On Github you have repositories. Think of them like document folders for different projects. Your Github account is essentially an online desk where you keep all of these folders/repositories inside and the underlying &lt;em&gt;git&lt;/em&gt; version control software is like the secretary. When you want to take a look at a particular project, you tell &lt;strong&gt;git&lt;/strong&gt; to give you a copy/&lt;strong&gt;clone&lt;/strong&gt; of the repository containing that project to keep on your own desk. This then becomes your local repository.&lt;/p&gt;
&lt;p&gt;You might then make some changes and add different things to the local repository. As you make changes you can make snapshots of your progress by telling git to &lt;strong&gt;commit&lt;/strong&gt; changes so you can revert to this point if you mess up later. Kind of like creating save files when you are playing a video game. Note that up to now all of your changes only happen in your local repository. Once you are really done for the night you can tell git to &lt;strong&gt;push&lt;/strong&gt; the changes to Github and git will make all the changes to the online repository to match your local repository.&lt;/p&gt;
&lt;p&gt;Github Pages is basically a special repository for you. Github will render html files inside this repository as webpages if someone types out the correponding url in a web browser. This means you can use this repository as a personal webhost and maintain it using git. That is what we are trying to achieve.&lt;/p&gt;
&lt;div id=&#34;setup-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setup&lt;/h3&gt;
&lt;p&gt;We are going to set everything up for a technique called &lt;em&gt;submodule&lt;/em&gt;. I will explain the reason later. In the mean time you should follow the steps below &lt;strong&gt;EXACTLY&lt;/strong&gt;.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Sign up for a (free) account on &lt;a href=&#34;https://github.com&#34;&gt;Github&lt;/a&gt;. Choose a reasonable username because that will be part of the URL pointing to your site.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Download and install &lt;a href=&#34;https://git-scm.com/downloads&#34;&gt;Git&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Configure it for RStudio by clicking on &lt;strong&gt;Tools&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; &lt;strong&gt;Global Options&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; &lt;strong&gt;Git/SVN&lt;/strong&gt;. Set the path to the git executable (default: &lt;code&gt;C:/Program Files/Git/bin/git.exe&lt;/code&gt;). Check the box for Using Git Bash.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on &lt;strong&gt;Create RSA Key…&lt;/strong&gt;. Leave everything at the default values (passphrase and confirm are blank) and click &lt;strong&gt;Create&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on &lt;strong&gt;View public key&lt;/strong&gt; and copy the text into clipboard.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;../../img/rstudio_ssh_key.png&#34; /&gt;

&lt;/div&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Go to &lt;a href=&#34;https://github.com&#34;&gt;Github&lt;/a&gt;, click on your profile on the top right and select &lt;strong&gt;Settings&lt;/strong&gt;. Click on &lt;strong&gt;SSH and GPG Keys&lt;/strong&gt; on the left and press the green &lt;strong&gt;New SSH key&lt;/strong&gt; button. Type whatever name you want for the title and paste the block of text you got from the last step into the &lt;strong&gt;Key&lt;/strong&gt; textfield. Add the key.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Creating Github Pages repository:&lt;/strong&gt; Go to Github. Click on New Repository. Select &lt;strong&gt;Initialize this repository with a README&lt;/strong&gt; so your repository comes with a README.md file. Name this repository &lt;em&gt;&amp;lt;github username&amp;gt;.github.io&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;../../img/github_repo.png&#34; /&gt;

&lt;/div&gt;
&lt;ol start=&#34;8&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Creating source repository:&lt;/strong&gt; Go back to the front page for Github and make another repository. The name doesn’t matter. I named mine &lt;em&gt;blog-source&lt;/em&gt;. However make sure you &lt;strong&gt;deselect&lt;/strong&gt; “Initialize this repository with a README”. Once the repository is created you should see a URL to this repository under Quick Setup in the form of &lt;code&gt;https://github.com/&amp;lt;github username&amp;gt;/&amp;lt;source repository name&amp;gt;.git&lt;/code&gt; Copy this into clipboard.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Launch RStudio. Click &lt;strong&gt;File&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; &lt;strong&gt;New Project…&lt;/strong&gt; and select &lt;strong&gt;Version Control&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; &lt;strong&gt;Git&lt;/strong&gt;. Paste the URL for your &lt;strong&gt;source repository&lt;/strong&gt; under Repository URL. Choose a location to create your local repository under and click Create Project. RStudio will automatically switch to your local respository afterwards.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We are now ready to generate our new site and configure it to use Github Pages as the webhost.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;site-creation-submodule&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Site Creation &amp;amp; Submodule&lt;/h2&gt;
&lt;p&gt;Here’s a bit of explanation on what we did before. Again, &lt;strong&gt;skip to Setup if you are not interested&lt;/strong&gt;. The reason we are using two repositories is because Hugo generates the website into a subdirectory called &lt;code&gt;public&lt;/code&gt;. Unfortunately, Github Pages for personal websites only serves homepage from the root of its master branch. To work around this we are going to link our &lt;code&gt;public&lt;/code&gt; directory in the local repository to our Github Pages repository while the root directory of our local repository remains linked to the source repository. Thus, if we commit then push changes in the root of our local repository, all the changes will go to the source repository. If we commit and push changes in the public subdirectory though, they will instead go into the Github Pages repo. As I have foreshadowed, this is realized using &lt;em&gt;submodule&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;setup-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setup&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;In RStudio, open the project we just created and make sure Blogdown is loaded using &lt;code&gt;library(&#39;blogdown&#39;)&lt;/code&gt;. Type &lt;code&gt;new_site()&lt;/code&gt; to create a blank site with the default theme. The homepage will show up in viewer. Click the red stop button to quit the viewer and go back to console.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Launch Git Bash terminal.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;../../img/git_shell.png&#34; /&gt;

&lt;/div&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;In the terminal, you should be in the directory for your local source repository. There should be a subdirectory called &lt;strong&gt;public&lt;/strong&gt;. Delete it with the command &lt;code&gt;rm -rf public&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the terminal, type the following command (one single line!) to clone your Github Pages repository into a subdirectory called &lt;code&gt;public&lt;/code&gt; using &lt;em&gt;submodule&lt;/em&gt;. Remember to replace with your own username.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;git submodule add -b master git@github.com:&amp;lt;username&amp;gt;/&amp;lt;username&amp;gt;.github.io.git public&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Double check by typing &lt;code&gt;git remote show origin&lt;/code&gt; in the terminal under the root directory of your local source repository. The origin should point to your &lt;strong&gt;online source repository&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Type &lt;code&gt;cd public&lt;/code&gt; and &lt;code&gt;git remote show origin&lt;/code&gt; again. This time it should point to your &lt;strong&gt;Github Pages repository&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In RStudio, you should see a file called .gitignore in RStudio’s file browser. Click on it to edit it. Add a new line &lt;code&gt;public/&lt;/code&gt; at the bottom. Save the file.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;site-configuration-and-deployment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Site Configuration and Deployment&lt;/h2&gt;
&lt;p&gt;Time to configure our site and deploy it for the first time!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The default theme is a bit barebones so you might want to install a new theme using the following command in RStudio with blogdown loaded:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install_theme(&amp;#39;&amp;lt;creator github name&amp;gt;/&amp;lt;theme name&amp;gt;&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, this blog site uses the &lt;a href=&#34;https://github.com/Vimux/Mainroad&#34;&gt;Mainroad&lt;/a&gt; theme. So I typed &lt;code&gt;install_theme(&#39;Vimux/Mainroad&#39;)&lt;/code&gt; to install it. Notice that there is no leading or trailing &lt;code&gt;/&lt;/code&gt;. After installation, open &lt;code&gt;config.toml&lt;/code&gt; in your root folder and double check that the variable &lt;code&gt;theme&lt;/code&gt; has been set to your theme of choice.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;To use &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; expressions you must enable the &lt;em&gt;mathjax&lt;/em&gt; javascript. I adopted YiHui Xie’s &lt;a href=&#34;https://github.com/yihui/hugo-lithium-theme/blob/7d436d803df90c873cdaecf24aeeff827696d77c/layouts/partials/footer.html#L21-L30&#34;&gt;approach&lt;/a&gt;. Copy the highlighted code chunk and insert it into a layout specification that you are sure to be loaded on every page by your theme. I inserted it into the footer.html file located under &lt;code&gt;themes/&amp;lt;theme name&amp;gt;/layouts/partials/&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There are other self-explanatory settings in &lt;strong&gt;config.toml&lt;/strong&gt; that you should change. For example, title, baseurl, author name and descriptions, etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use &lt;code&gt;new_post(&#39;&amp;lt;title&amp;gt;&#39;)&lt;/code&gt; to create a new blog post as a .Rmd file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you want a preview of your site, type &lt;code&gt;serve_site()&lt;/code&gt; in RStudio to start a local server with a copy of your website on display.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you are satisfied, build the online version of the site using the &lt;code&gt;build_site()&lt;/code&gt; command in RStudio. After that you can use git to push the web pages inside your &lt;strong&gt;public/&lt;/strong&gt; folder into the Github Pages repository. I have modified &lt;a href=&#34;https://hjdskes.github.io/blog/update-deploying-hugo-on-personal-gh-pages/&#34;&gt;Jente Hidske&lt;/a&gt;’s shell script into a R script to streamline deployment:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Customized R function to facilitate fast site deployment
require(blogdown)

deploy &amp;lt;- function() {
    
    # Make sure things are commited
    output &amp;lt;- system(&amp;#39;git status -s&amp;#39;, intern = TRUE)
    
    if (length(output)) {
        print(&amp;#39;Dirty work directory. Commit/revert changed files first.&amp;#39;)
    } else {
        # Remove old website
        unlink(list.files(path = &amp;#39;./public&amp;#39;, full.names = TRUE), 
               recursive = TRUE)
        
        # Build website from source
        build_site()
        
        # Push site
        message &amp;lt;- paste(&amp;#39;Site rebuild&amp;#39;, as.character(Sys.time()))
        setwd(&amp;#39;./public&amp;#39;)
        
        fileConn&amp;lt;-file(&amp;quot;deploy.sh&amp;quot;)
        writeLines(c(&amp;#39;git add -A&amp;#39;,
                     paste(&amp;#39;git commit -m&amp;#39;, &amp;#39; \&amp;quot;&amp;#39;, message, &amp;#39;\&amp;quot;&amp;#39;, sep = &amp;#39;&amp;#39;), 
                     &amp;#39;git push&amp;#39;), 
                   fileConn)
        close(fileConn)
        
        setwd(&amp;#39;..&amp;#39;)
        print(message)
        print(&amp;#39;Go to ./public and execute ./deploy.sh&amp;#39;)
        
    }
    
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you copy the above code into an empty .R script file, save it as deploy.R and use &lt;code&gt;source(&#39;deploy.R&#39;)&lt;/code&gt; to load the script into memory. Whenever you want to deploy your site, first commit your changes to the local source repository (ie: by RStudio Git GUI or command line), then type &lt;code&gt;deploy()&lt;/code&gt; in RStudio to build the site. Once that is done, go to the terminal and type &lt;code&gt;cd public&lt;/code&gt; to go to the Github Pages local repository. Type &lt;code&gt;./deploy.sh&lt;/code&gt; to complete deployment.&lt;/p&gt;
&lt;p&gt;I also recommend that you create a file named &lt;strong&gt;.Rprofile&lt;/strong&gt; in the root of your local source repository. Inside I put common commands that I want RStudio to run every time it loads the project for the website. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Required library/files
library(blogdown)
source(&amp;#39;deploy.R&amp;#39;)

# Default Options
options(blogdown.author = &amp;#39;&amp;lt;your name here&amp;gt;&amp;#39;)
options(blogdown.rmd = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Making A Blog Site with RStudio, R Markdown and Blogdown Part I</title>
      <link>https://fengkehh.github.io/post/2017-03-15-how-this-blog-is-made/</link>
      <pubDate>Wed, 15 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://fengkehh.github.io/post/2017-03-15-how-this-blog-is-made/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;
&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;
&lt;p&gt;This blog is made of one philosophy resting on four pillars: it should cost exactly nothing and all the software you need are the following.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The R programming language for data analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The R Markdown language for content generation and typesetting.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Blogdown in conjunction with Hugo to generate the web pages.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Github-Pages for webhosting.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This post will mainly touch on 1 and 2. &lt;a href=&#34;../2017-03-16-how-this-blog-is-made-part-ii/&#34;&gt;Part II&lt;/a&gt; will focus on 3 and 4 so you can get your own blog up and running if you want to follow in my footsteps.&lt;/p&gt;
&lt;div id=&#34;the-r-programming-language&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The R Programming Language&lt;/h2&gt;
&lt;p&gt;R is a programming language designed for statistical computation. It has very powerful data manipulation and 2d plotting capabilities. However to use it to its full potential you need to let go of graphical user interfaces and start writing R scripts. If you have always relied on GUI before, you should know that having to code everything is a good thing! Imagine having to explain to someone which buttons to click and how far he has to move the slider to get the same result you have. If you did everything in R all you need to do is just showing them the code.&lt;/p&gt;
&lt;p&gt;To get R up and running on your computer, download and install the R distribution for your operating system from the &lt;a href=&#34;https://cran.r-project.org/&#34;&gt;official website&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-markdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R Markdown&lt;/h2&gt;
&lt;p&gt;Perhaps the most important reason to create a blog site this way is none other than R Markdown. You can think of R Markdown as a language that allows you to quickly generate decent looking webpages with embedded R codes, graphics and even &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; expressions for mathematical equations. It is an incredibly efficient language in the sense that almost every single thing you type goes directly to the content you want to show to your audience as opposed to tweaking various display or formatting parameters.&lt;/p&gt;
&lt;p&gt;I use the popular &lt;a href=&#34;https://www.rstudio.com/products/rstudio/#Desktop&#34;&gt;RStudio&lt;/a&gt; to write R Markdown files. Be sure to install R first if you haven’t done so already.&lt;/p&gt;
&lt;p&gt;Once you have RStudio installed go ahead and launch it. Type the following lines in the console to install all the packages you need for R Markdown:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;#39;rmarkdown&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I won’t go into how to use RStudio or write R Markdown files here because there are many excellent &lt;a href=&#34;https://www.r-bloggers.com/r-markdown-and-knitr-tutorial-part-1/&#34;&gt;tutorials&lt;/a&gt; on the subject already. The reason I bring them up is because there are nice tools out there that help us convert content generated by R Markdown to content readable on a blog like this one. &lt;a href=&#34;../2017-03-16-how-this-blog-is-made-part-ii/&#34;&gt;Part II&lt;/a&gt; will talk about how to set up free webhosting using Github-Pages and configure Blogdown and Hugo to generate the static webpages for the blog site.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>